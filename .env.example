# Environment Variables for Finnish Legal AI System
# For deployment (Streamlit Cloud, Replit, etc.): see DEPLOY.md "Environment variables for deployment".

# ============================================================================
# Supabase Configuration
# ============================================================================
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-anon-or-service-key-here

# Note: For schema setup, you may need the service_role key
# Find it in: Supabase Dashboard → Settings → API → service_role
# SUPABASE_SERVICE_KEY=your-service-role-key-here

# ============================================================================
# OpenAI Configuration (for embeddings)
# ============================================================================
OPENAI_API_KEY=your-openai-api-key-here

# ============================================================================
# Cohere Configuration (for re-ranking)
# ============================================================================
COHERE_API_KEY=your-cohere-api-key-here

# ============================================================================
# LangSmith for Tracing & Observability
# Get your API key from: https://smith.langchain.com
# ============================================================================
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=your-langsmith-api-key-here
LANGSMITH_PROJECT=ai-legal-reasoning

# ============================================================================
# Application Settings
# ============================================================================
# Embedding model configuration
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# Retrieval settings
VECTOR_SEARCH_TOP_K=30
FTS_SEARCH_TOP_K=30
RERANK_TOP_K=10
# Candidates fetched before rerank; then how many chunks sent to the LLM (default 10)
SEARCH_CANDIDATES_FOR_RERANK=30
CHUNKS_TO_LLM=10
# Set to false to disable multi-query expansion (saves 1 LLM call per question; only original query is used)
MULTI_QUERY_ENABLED=false
# When true: skip multi-query when user mentions a case ID (e.g. KKO:2024:76); saves 2 LLM calls + 2 hybrid searches
MULTI_QUERY_SKIP_WHEN_CASE_ID=true
# Set to false to skip reformulation (when search returns 0 results, go straight to apology; no query rewrite retry)
REFORMULATE_ENABLED=true
# When true: ask for year range when legal query has no case ID and no year (e.g. "What is theft penalty?")
YEAR_CLARIFICATION_ENABLED=true
# Max documents sent to Cohere rerank (fewer = faster; default 20 for production)
RERANK_MAX_DOCS=20
# Set to false to skip Cohere rerank (fast mode; saves ~15-25s; uses hybrid + RRF only)
RERANK_ENABLED=false
# Cohere rerank model (e.g. rerank-multilingual-v3.0 or rerank-v4.0-fast)
COHERE_RERANK_MODEL=rerank-v4.0-fast
# Set to true to run relevancy check after answer (adds ~2-5s)
RELEVANCY_CHECK_ENABLED=false
SIMILARITY_THRESHOLD=0.5
MATCH_THRESHOLD=0.3

# Query length limit (chars). Reject oversize queries to avoid abuse and cost.
MAX_QUERY_LENGTH=2000

# Ingestion: set to false for regex-only extraction (no LLM during ingest; saves cost)
USE_AI_EXTRACTION=false
# When true: skip documents with same content_hash in Supabase (faster). When false: always re-run and re-store (re-ingest).
INGESTION_SKIP_UNCHANGED=false
# Reduce Supabase Disk IO: pause every N documents (0 = disabled). Example: INGESTION_DOC_DELAY_EVERY=25 INGESTION_DOC_DELAY_SECONDS=0.5
# INGESTION_DOC_DELAY_EVERY=25
# INGESTION_DOC_DELAY_SECONDS=0.5

# Chunking settings
CHUNK_SIZE=1000
CHUNK_MIN_SIZE=100
CHUNK_OVERLAP=50

# PDF processing (parallel workers)
PDF_MAX_WORKERS=4

# Logging: LOG_LEVEL=DEBUG|INFO|WARNING|ERROR, LOG_FORMAT=simple for human-readable
LOG_LEVEL=INFO

# Case law ingestion (production: no local .json cache/backup)
# CASE_LAW_NO_JSON_CACHE=1

# ------------------------------------------------------------------------------
# Case law PDF backup to Google Drive (separate pipeline)
# ------------------------------------------------------------------------------
# 1 = write PDFs locally and upload to Drive (development). 0 = upload to Drive only, no local folder (production).
CASE_LAW_EXPORT_LOCAL=1

# Local folder for exported PDFs when CASE_LAW_EXPORT_LOCAL=1 (ignored when 0). Default: data/case_law_export
CASE_LAW_EXPORT_ROOT=data/case_law_export

# Google Drive: root folder ID (from Drive URL .../folders/FOLDER_ID).
GOOGLE_DRIVE_ROOT_FOLDER_ID=

# OAuth2 client secret JSON (Desktop app): recommended for personal Drive. Never commit the key file.
GOOGLE_OAUTH_CLIENT_SECRET=

# Service account JSON key (fallback, only for Shared Drives):
# GOOGLE_APPLICATION_CREDENTIALS=your-service-account-key.json

# ------------------------------------------------------------------------------
# Multi-Tenant Client Document Ingestion
# ------------------------------------------------------------------------------
# Set to isolate client documents. Each tenant sees only their own docs + public case law.
# Leave empty for no tenant isolation (all data visible to all users).
LEXAI_TENANT_ID=

# Google Drive OAuth (web flow) for client document ingestion from Google Drive.
# Create a Web Application OAuth client at https://console.cloud.google.com/apis/credentials
GOOGLE_DRIVE_CLIENT_ID=
GOOGLE_DRIVE_CLIENT_SECRET=

# Microsoft OneDrive OAuth for client document ingestion from OneDrive.
# Register an app at https://portal.azure.com/#blade/Microsoft_AAD_RegisteredApps
MICROSOFT_CLIENT_ID=
MICROSOFT_CLIENT_SECRET=
